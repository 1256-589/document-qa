import streamlit as st
from PyPDF2 import PdfReader
from langchain import hub
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.vectorstores import FAISS
from langchain.tools.retriever import create_retriever_tool
from langchain.agents import AgentExecutor, create_tool_calling_agent, create_openai_tools_agent
from langchain_community.embeddings import DashScopeEmbeddings
from langchain.chat_models import init_chat_model
from langchain_community.tools import DuckDuckGoSearchRun, TavilySearchResults
from langchain.tools import Tool
from langchain_core.messages import AIMessage, HumanMessage
import os
from dotenv import load_dotenv
import shutil
import time
import pickle
from datetime import datetime

from langchain_core.tools import tool

# --- åˆå§‹åŒ–ä¸é…ç½® ---
load_dotenv(override=True)
st.set_page_config(page_title="RAG ç ”ç©¶åŠ©æ‰‹", page_icon="ğŸ’¡")

# --- å¸¸é‡å®šä¹‰ ---
DB_DIR = "document_database"
FILES_DIR = os.path.join(DB_DIR, "files")
INDEX_PATH = os.path.join(DB_DIR, "faiss_index")
CHAT_HISTORY_DIR = "chat_history"
ACTIVE_CHAT_FILE = os.path.join(CHAT_HISTORY_DIR, "active_session.pkl")


# --- åç«¯è¾…åŠ©å‡½æ•° (æ— éœ€ä¿®æ”¹) ---
@st.cache_resource
def get_embeddings():
    # å®é™…é¡¹ç›®ä¸­ï¼ŒAPI Keyä¸åº”ç¡¬ç¼–ç ï¼Œè€Œæ˜¯é€šè¿‡ç¯å¢ƒå˜é‡ç­‰æ–¹å¼ç®¡ç†
    return DashScopeEmbeddings(model="text-embedding-v2", dashscope_api_key=os.getenv("DASHSCOPE_API_KEY"))



embeddings = get_embeddings()

def setup_directories():
    os.makedirs(FILES_DIR, exist_ok=True)
    os.makedirs(CHAT_HISTORY_DIR, exist_ok=True)


def save_chat_history(history, file_path):
    os.makedirs(os.path.dirname(file_path), exist_ok=True)
    with open(file_path, "wb") as f:
        pickle.dump(history, f)


def load_chat_history(file_path):
    if os.path.exists(file_path):
        try:
            with open(file_path, "rb") as f:
                return pickle.load(f)
        except (pickle.UnpicklingError, EOFError):
            pass
    return [AIMessage(content="æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„AIç ”ç©¶åŠ©æ‰‹ã€‚")]

def process_and_index_files(pdf_docs,progress_placeholder):
    """Processes uploaded PDF files, saves them, and indexes their content."""
    texts_with_metadata = []
    progress_bar = progress_placeholder.progress(0, text="å¼€å§‹å¤„ç†æ–‡ä»¶...")
    for pdf in pdf_docs:
        # Save the file to the persistent storage
        file_path = os.path.join(FILES_DIR, pdf.name)
        with open(file_path, "wb") as f:
            f.write(pdf.getbuffer())

        # Extract text and create chunks with metadata
        pdf_reader = PdfReader(file_path)
        for page in pdf_reader.pages:
            text = page.extract_text()
            if text:
                text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
                chunks = text_splitter.split_text(text)
                for chunk in chunks:
                    # Crucially, add the source filename to each chunk's metadata
                    texts_with_metadata.append((chunk, {"source": pdf.name}))

    if not texts_with_metadata:
        return 0

    # Separate texts and metadatas for FAISS
    texts = [item[0] for item in texts_with_metadata]
    metadatas = [item[1] for item in texts_with_metadata]

    if os.path.exists(INDEX_PATH):
        # Load existing index and add new texts
        db = FAISS.load_local(INDEX_PATH, embeddings, allow_dangerous_deserialization=True)
        db.add_texts(texts, metadatas=metadatas)
    else:
        # Create a new index
        db = FAISS.from_texts(texts, embeddings, metadatas=metadatas)
    progress_bar.progress(1.0, text="å¤„ç†å®Œæˆï¼")

    db.save_local(INDEX_PATH)
    return len(pdf_docs)


# def process_and_index_files(pdf_docs, progress_placeholder):
#     texts_with_metadata = []
#     progress_bar = progress_placeholder.progress(0, text="å¼€å§‹å¤„ç†æ–‡ä»¶...")
#     for i, pdf in enumerate(pdf_docs):
#         progress_bar.progress((i) / len(pdf_docs), text=f"æ­£åœ¨å¤„ç†: {pdf.name}")
#         file_path = os.path.join(FILES_DIR, pdf.name)
#         with open(file_path, "wb") as f:
#             f.write(pdf.getbuffer())
#         try:
#             pdf_reader = PdfReader(file_path)
#             for page in pdf_reader.pages:
#                 text = page.extract_text()
#                 if text:
#                     text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
#                     chunks = text_splitter.split_text(text)
#                     for chunk in chunks:
#                         texts_with_metadata.append((chunk, {"source": pdf.name}))
#         except Exception as e:
#             st.error(f"å¤„ç†æ–‡ä»¶ {pdf.name} æ—¶å‡ºé”™: {e}")
#             continue
#
#     if not texts_with_metadata:
#         progress_bar.empty()
#         st.warning("æœªèƒ½ä»æ–‡ä»¶ä¸­æå–ä»»ä½•æ–‡æœ¬ã€‚")
#         return 0
#
#     progress_bar.progress(0.9, text="æ­£åœ¨åˆ›å»ºå‘é‡ç´¢å¼•...")
#     embeddings = get_embeddings()
#     texts = [item[0] for item in texts_with_metadata]
#     metadatas = [item[1] for item in texts_with_metadata]
#     if os.path.exists(INDEX_PATH):
#         db = FAISS.load_local(INDEX_PATH, embeddings, allow_dangerous_deserialization=True)
#         db.add_texts(texts, metadatas=metadatas)
#     else:
#         db = FAISS.from_texts(texts, embeddings, metadatas=metadatas)
#     db.save_local(INDEX_PATH)
#     progress_bar.progress(1.0, text="å¤„ç†å®Œæˆï¼")
#     time.sleep(1)
#     progress_bar.empty()
#     return len(pdf_docs)


def get_relevant_files(query):
    """Searches the entire database to find files relevant to the query."""
    if not os.path.exists(INDEX_PATH):
        return []

    db = FAISS.load_local(INDEX_PATH, embeddings, allow_dangerous_deserialization=True)
    retriever = db.as_retriever(search_kwargs={'k': 20})  # Get top 5 most relevant chunks
    relevant_docs = retriever.get_relevant_documents(query)
    # print(relevant_docs)

    # Extract unique source filenames from metadata
    relevant_files = list(set(doc.metadata['source'] for doc in relevant_docs))
    return relevant_files


def get_agent_executor(selected_files=None):
    """Creates an agent with tools. The document retriever is filtered by selected files."""
    search = TavilySearchResults(max_results=6)
    @tool
    def search_tool(name: str) -> str:
        """å½“ä½ éœ€è¦æœç´¢æˆ–è€…æŸ¥è¯¢çš„æ—¶å€™ä½¿ç”¨æ­¤å·¥å…·ã€‚"""
        print("æ­£åœ¨ä½¿ç”¨å·¥å…·è¿›è¡Œæœç´¢ï¼š")
        return search.invoke(name)
    tools = [search_tool]
    # 2. Document Retriever Tool (if files are selected)
    if selected_files:
        full_db = FAISS.load_local(INDEX_PATH, embeddings, allow_dangerous_deserialization=True)

        # 2. æ ¹æ®ç”¨æˆ·çš„é€‰æ‹©ï¼Œåœ¨å†…å­˜ä¸­è¿‡æ»¤æ–‡æ¡£ã€‚
        # æˆ‘ä»¬ç›´æ¥è®¿é—® docstoreï¼Œå®ƒä¿å­˜äº†æ‰€æœ‰çš„æ–‡æ¡£(Document)å¯¹è±¡åŠå…¶å…ƒæ•°æ®ã€‚
        filtered_docs = []
        for doc_id, doc in full_db.docstore._dict.items():
            if doc.metadata.get("source") in selected_files:
                filtered_docs.append(doc)

        # 3. å¦‚æœæ‰¾åˆ°äº†åŒ¹é…çš„æ–‡æ¡£ï¼Œå°±ç”¨å®ƒä»¬åœ¨å†…å­˜ä¸­åˆ›å»ºä¸€ä¸ªå…¨æ–°çš„ã€ä¸´æ—¶çš„ FAISS ç´¢å¼•ã€‚
        # è¿™ç§æ–¹å¼æ—¢é«˜æ•ˆåˆèƒ½ä¿è¯æ£€ç´¢å™¨åªåœ¨è¿™äº›ç‰¹å®šçš„æ–‡æ¡£ä¸­è¿›è¡Œæœç´¢ã€‚
        if filtered_docs:
            # ä»è¿‡æ»¤åçš„æ–‡æ¡£åˆ—è¡¨åˆ›å»ºæ–°çš„ FAISS æ•°æ®åº“
            filtered_db = FAISS.from_documents(filtered_docs, embeddings)
            # åŸºäºè¿™ä¸ªä¸´æ—¶çš„ã€å·²è¿‡æ»¤çš„æ•°æ®åº“åˆ›å»ºæ£€ç´¢å™¨
            retriever = filtered_db.as_retriever(search_kwargs={'k': 5})

            # 4. ä½¿ç”¨è¿™ä¸ªè¢«å®Œç¾è¿‡æ»¤çš„ã€å…¨æ–°çš„æ£€ç´¢å™¨æ¥åˆ›å»ºå·¥å…·ã€‚
            document_retriever = create_retriever_tool(
                retriever,
                "document_retriever",
                f"""è¯·ä¼˜å…ˆä½¿ç”¨æ­¤å·¥å…·è¿›è¡ŒæŸ¥è¯¢å’Œç”¨æˆ·é—®é¢˜ç›¸å…³çš„èƒŒæ™¯çŸ¥è¯†ã€‚
            è¿™æ˜¯å›ç­”å…³äºæ–‡æ¡£ '{', '.join(selected_files)}' å…·ä½“å†…å®¹é—®é¢˜çš„å”¯ä¸€å¯é ä¿¡æ¯æ¥æºã€‚
            ä¾‹å¦‚ï¼Œå½“è¢«é—®åŠâ€œæ–‡æ¡£ä¸­çš„ä¸»è¦è§‚ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿâ€æˆ–â€œXXé¡¹ç›®çš„æˆªæ­¢æ—¥æœŸæ˜¯å“ªå¤©ï¼Ÿâ€æ—¶ï¼Œåº”ä½¿ç”¨æ­¤å·¥å…·ã€‚"""
            )
            tools.append(document_retriever)

    llm = init_chat_model("deepseek-chat", model_provider="deepseek")
    # print(tools)

    prompt = hub.pull("hwchase17/openai-tools-agent")

    agent = create_openai_tools_agent(llm, tools, prompt)
    aa = AgentExecutor(agent=agent, tools=tools, verbose=True)
    # print(aa.invoke({"input":"å¦‚ä½•è¯„ä»·ã€Šæ„¿ä¸æ„ã€‹"}))
    return aa


# --- ä¸»ç¨‹åºå…¥å£ ---
def main():
    setup_directories()

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = load_chat_history(ACTIVE_CHAT_FILE)
    if "rag_active" not in st.session_state:
        st.session_state.rag_active = True
    if "file_selection" not in st.session_state:
        st.session_state.file_selection = {"show": False, "query": None, "options": []}
    if "sidebar_view" not in st.session_state:
        st.session_state.sidebar_view = "å†å²è®°å½•"

    # --- ä¾§è¾¹æ  UI ---
    with st.sidebar:
        st.header("RAG ç ”ç©¶åŠ©æ‰‹")
        if st.button("ğŸ“ å‘èµ·æ–°å¯¹è¯", use_container_width=True, type="primary"):
            if os.path.exists(ACTIVE_CHAT_FILE) and len(st.session_state.chat_history) > 1:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                archive_file = os.path.join(CHAT_HISTORY_DIR, f"history_{timestamp}.pkl")
                shutil.copy(ACTIVE_CHAT_FILE, archive_file)
                st.toast(f"å…ˆå‰çš„å¯¹è¯å·²å­˜æ¡£ã€‚", icon="âœ…")
            st.session_state.chat_history = [AIMessage(content="æ‚¨å¥½ï¼æ–°çš„å¯¹è¯å·²å¼€å¯ã€‚")]
            st.session_state.file_selection = {"show": False, "query": None, "options": []}  # æ¸…ç©ºæ–‡ä»¶é€‰æ‹©
            save_chat_history(st.session_state.chat_history, ACTIVE_CHAT_FILE)
            st.rerun()

        st.markdown("---")

        # ä¾§è¾¹æ è§†å›¾åˆ‡æ¢
        st.session_state.sidebar_view = st.radio(
            "æŸ¥çœ‹:",
            ["å†å²è®°å½•", "æ–‡æ¡£æ•°æ®åº“"],
            horizontal=True,
            label_visibility="collapsed"
        )

        # --- åŠ¨æ€å†…å®¹åŒºåŸŸ ---
        if st.session_state.sidebar_view == "å†å²è®°å½•":
            st.subheader("ğŸ—‚ï¸ å†å²è®°å½•")
            archived_files = sorted([f for f in os.listdir(CHAT_HISTORY_DIR) if f.startswith("history_")], reverse=True)
            if not archived_files:
                st.info("æ²¡æœ‰å†å²è®°å½•ã€‚")
            else:
                for file in archived_files:
                    ts_str = file.replace("history_", "").replace(".pkl", "")
                    label = f"å¯¹è¯äº {datetime.strptime(ts_str, '%Y%m%d_%H%M%S').strftime('%y-%m-%d %H:%M')}"
                    if st.button(label, key=file, use_container_width=True):
                        st.session_state.chat_history = load_chat_history(os.path.join(CHAT_HISTORY_DIR, file))
                        save_chat_history(st.session_state.chat_history, ACTIVE_CHAT_FILE)
                        st.toast(f"å·²åŠ è½½ä¼šè¯: {label}")
                        st.rerun()
        else:  # æ–‡æ¡£æ•°æ®åº“è§†å›¾
            st.subheader("ğŸ“š æ–‡æ¡£æ•°æ®åº“")
            search_term = st.text_input("ğŸ” æœç´¢æ–‡æ¡£...", placeholder="è¾“å…¥æ–‡ä»¶åå…³é”®å­—...",
                                        label_visibility="collapsed")
            indexed_files = [f for f in os.listdir(FILES_DIR) if f.endswith('.pdf')] if os.path.exists(
                FILES_DIR) else []
            if search_term:
                indexed_files = [f for f in indexed_files if search_term.lower() in f.lower()]
            if not indexed_files:
                st.info("æ•°æ®åº“ä¸ºç©ºæˆ–æœªæ‰¾åˆ°åŒ¹é…é¡¹ã€‚")
            else:
                st.caption(f"æ‰¾åˆ° {len(indexed_files)} ä¸ªæ–‡ä»¶")
                for file_name in indexed_files:
                    st.markdown(f"ğŸ“„ `{file_name}`")

        # --- å›ºå®šçš„æ–‡æ¡£ç®¡ç†åŒºåŸŸ ---
        st.markdown("---")
        with st.expander("âš™ï¸ æ–‡æ¡£ç®¡ç†"):
            pdf_docs = st.file_uploader("ä¸Šä¼ æ–°PDF", accept_multiple_files=True, type=['pdf'])
            progress_placeholder = st.empty()
            if st.button("å¤„ç†å¹¶ç´¢å¼•", disabled=not pdf_docs, use_container_width=True):
                count = process_and_index_files(pdf_docs, progress_placeholder)
                if count > 0:
                    st.success(f"æˆåŠŸå¤„ç†å¹¶ç´¢å¼•äº† {count} ä¸ªæ–°æ–‡ä»¶ã€‚")

            st.markdown("---")
            if st.button("ğŸ”¥ æ¸…ç©ºæ‰€æœ‰æ•°æ®", use_container_width=True):
                confirm_check = st.checkbox("æˆ‘ç¡®è®¤è¦æ°¸ä¹…åˆ é™¤æ‰€æœ‰æ–‡æ¡£å’Œå†å²è®°å½•ã€‚")
                if confirm_check:
                    if os.path.exists(DB_DIR): shutil.rmtree(DB_DIR)
                    if os.path.exists(CHAT_HISTORY_DIR): shutil.rmtree(CHAT_HISTORY_DIR)
                    st.session_state.chat_history = [AIMessage(content="æ‰€æœ‰æ•°æ®å‡å·²æ¸…é™¤ã€‚")]
                    st.success("æ‰€æœ‰æ•°æ®å·²è¢«æ¸…ç©ºã€‚")
                    time.sleep(1)
                    st.rerun()

    # --- ä¸»èŠå¤©ç•Œé¢ (å§‹ç»ˆæ˜¾ç¤º) ---
    col1, col2 = st.columns([0.8, 0.2])
    with col1:
        st.subheader("å½“å‰å¯¹è¯")
    with col2:
        st.session_state.rag_active = st.toggle("æ¿€æ´» RAG", value=st.session_state.rag_active,
                                                help="æ¿€æ´»åï¼Œå°†ä¼˜å…ˆåœ¨æ‚¨ä¸Šä¼ çš„æ–‡æ¡£ä¸­å¯»æ‰¾ç­”æ¡ˆã€‚")

    # RAG æ–‡ä»¶é€‰æ‹©ç•Œé¢
    if st.session_state.file_selection.get("show"):
        with st.chat_message("AI", avatar="ğŸ’¡"):
            st.info("æ ¹æ®æ‚¨çš„é—®é¢˜ï¼Œæˆ‘æ‰¾åˆ°äº†è¿™äº›å¯èƒ½ç›¸å…³çš„æ–‡æ¡£ã€‚")
            selected_files = st.multiselect(
                "è¯·é€‰æ‹©æ‚¨å¸Œæœ›æˆ‘ä½¿ç”¨çš„æ–‡ä»¶ï¼š",
                options=st.session_state.file_selection["options"],
                default=st.session_state.file_selection["options"]
            )
            if st.button("åŸºäºæ‰€é€‰æ–‡ä»¶ç”Ÿæˆå›ç­”", type="primary"):
                with st.spinner("æ€è€ƒä¸­..."):
                    query = st.session_state.file_selection["query"]
                    st.session_state.chat_history.append(HumanMessage(content=query))
                    agent_executor = get_agent_executor(selected_files)
                    response = agent_executor.invoke(
                        {"input": "è¯·ä¼˜å…ˆæ£€ç´¢æœ¬åœ°æ–‡ä»¶åå›ç­”ä¸‹é¢çš„é—®é¢˜:"+query, "chat_history": st.session_state.chat_history[1:-1]})
                    st.session_state.chat_history.append(AIMessage(content=response['output']))
                    save_chat_history(st.session_state.chat_history, ACTIVE_CHAT_FILE)
                    st.session_state.file_selection["show"] = False
                    st.rerun()
    else:
        # èŠå¤©è®°å½•å±•ç¤º
        for message in st.session_state.chat_history:
            avatar = "ğŸ’¡" if isinstance(message, AIMessage) else "ğŸ§‘â€ğŸ’»"
            with st.chat_message(message.type, avatar=avatar):
                st.write(message.content)

    # ç”¨æˆ·è¾“å…¥å¤„ç†
    if user_query := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
        if st.session_state.rag_active and os.path.exists(INDEX_PATH):
            relevant_files = get_relevant_files(user_query)
            if relevant_files:
                st.session_state.file_selection = {"show": True, "query": user_query, "options": relevant_files}
                st.rerun()
            else:
                st.toast("æœªåœ¨æ‚¨çš„æ–‡æ¡£åº“ä¸­æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ï¼Œå°†å°è¯•è”ç½‘æœç´¢ã€‚", icon="ğŸŒ")

        if not st.session_state.file_selection.get("show"):
            st.session_state.chat_history.append(HumanMessage(content=user_query))
            with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"):
                st.write(user_query)
            with st.spinner("æ€è€ƒä¸­..."):
                agent_executor = get_agent_executor()
                # print(st.session_state.chat_history[1:-1])
                response = agent_executor.invoke(
                    {"input": user_query, "chat_history": st.session_state.chat_history[1:-1]})
                st.session_state.chat_history.append(AIMessage(content=response['output']))
                save_chat_history(st.session_state.chat_history, ACTIVE_CHAT_FILE)
                st.rerun()


if __name__ == "__main__":
    main()
