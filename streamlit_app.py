from io import StringIO
import pandas as pd
import streamlit as st
from PyPDF2 import PdfReader
from langchain import hub
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.agents import AgentAction
from langchain_core.callbacks import BaseCallbackHandler
from langchain_community.vectorstores import FAISS
from langchain.tools.retriever import create_retriever_tool
from langchain.agents import AgentExecutor, create_openai_tools_agent, create_tool_calling_agent
from langchain_community.embeddings import DashScopeEmbeddings
from langchain.chat_models import init_chat_model
from langchain_community.tools import TavilySearchResults
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import tool
from langchain_core.messages import AIMessage, HumanMessage
import os
from dotenv import load_dotenv
import shutil
import time
import pickle
from datetime import datetime

from langchain_experimental.tools import PythonAstREPLTool

# --- åˆå§‹åŒ–ä¸é…ç½® ---
load_dotenv(override=True)
st.set_page_config(page_title="AI ç ”ç©¶åŠ©æ‰‹", page_icon="ğŸ’¡")

# --- å¸¸é‡å®šä¹‰ ---
DB_DIR = "document_database"
FILES_DIR = os.path.join(DB_DIR, "files")
INDEX_PATH = os.path.join(DB_DIR, "faiss_index")
CHAT_HISTORY_DIR = "chat_history"
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"


# --- åç«¯è¾…åŠ©å‡½æ•° ---
@st.cache_resource
def get_embeddings():
    return DashScopeEmbeddings(model="text-embedding-v3", dashscope_api_key=os.getenv("DASHSCOPE_API_KEY"))


embeddings = get_embeddings()


def setup_directories():
    os.makedirs(FILES_DIR, exist_ok=True)
    os.makedirs(CHAT_HISTORY_DIR, exist_ok=True)


# --- æ•°æ®å­˜å‚¨å‡½æ•° (é‡å¤§ä¿®æ”¹) ---
def save_chat_history(title, messages, file_path):
    """ä¿å­˜å¯¹è¯æ ‡é¢˜å’Œæ¶ˆæ¯åˆ° Pickle æ–‡ä»¶"""
    if not file_path:
        st.error("é”™è¯¯ï¼šæ²¡æœ‰æä¾›æœ‰æ•ˆçš„å¯¹è¯æ–‡ä»¶è·¯å¾„ç”¨äºä¿å­˜ï¼")
        return
    os.makedirs(os.path.dirname(file_path), exist_ok=True)
    with open(file_path, "wb") as f:
        pickle.dump({"title": title, "messages": messages}, f)


def load_chat_history(file_path):
    """ä» Pickle æ–‡ä»¶åŠ è½½å¯¹è¯ï¼Œè¿”å› (æ ‡é¢˜, æ¶ˆæ¯åˆ—è¡¨)"""
    if os.path.exists(file_path):
        try:
            with open(file_path, "rb") as f:
                data = pickle.load(f)
                # å…¼å®¹æ–°æ—§ä¸¤ç§æ•°æ®æ ¼å¼
                if isinstance(data, dict):
                    return data.get("title"), data.get("messages", [])
                elif isinstance(data, list):
                    return None, data  # æ—§æ ¼å¼ï¼Œæ²¡æœ‰æ ‡é¢˜
        except (pickle.UnpicklingError, EOFError):
            return "æŸåçš„å¯¹è¯", [AIMessage(content="æ— æ³•åŠ è½½å¯¹è¯ï¼Œæ–‡ä»¶å¯èƒ½å·²æŸåã€‚")]
    return None, []


def get_chat_title_from_file(file_path):
    """åªè¯»å–æ ‡é¢˜ï¼Œç”¨äºåœ¨ä¾§è¾¹æ å¿«é€Ÿæ˜¾ç¤ºï¼Œé¿å…åŠ è½½æ•´ä¸ªå¯¹è¯å†å²"""
    title, _ = load_chat_history(file_path)
    return title


# --- LLM ç›¸å…³å‡½æ•° ---
def generate_chat_title(query):
    """è°ƒç”¨LLMä¸ºå¯¹è¯ç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„æ ‡é¢˜"""
    st.toast("æ­£åœ¨ä¸ºæ–°å¯¹è¯ç”Ÿæˆæ ‡é¢˜...", icon="ğŸ·ï¸")
    title_prompt = ChatPromptTemplate.from_messages([
        ("system", "ä½ æ˜¯ä¸€ä¸ªæ–‡æœ¬æ‘˜è¦åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„æé—®ï¼Œä¸ºè¿™ä¸ªå¯¹è¯ç”Ÿæˆä¸€ä¸ªä¸è¶…è¿‡8ä¸ªå­—çš„ã€ç®€çŸ­ç²¾ç‚¼çš„æ ‡é¢˜ã€‚"),
        ("user", "{query}")
    ])
    # ä¸ºäº†èŠ‚çœæˆæœ¬å’Œæé«˜é€Ÿåº¦ï¼Œå¯ä»¥ä½¿ç”¨ä¸€ä¸ªè¾ƒå°çš„æ¨¡å‹
    llm = init_chat_model("deepseek-chat", model_provider="deepseek", temperature=0.1)
    chain = title_prompt | llm
    try:
        response = chain.invoke({"query": query})
        return response.content.strip().replace("\"", "")
    except Exception as e:
        print(f"æ ‡é¢˜ç”Ÿæˆå¤±è´¥: {e}")
        return "æ–°å¯¹è¯"


# ... (process_and_index_files, get_relevant_files, get_agent_executor, run_agent_with_streaming å‡½æ•°ä¿æŒä¸å˜) ...
def process_and_index_files(pdf_docs, progress_placeholder):
    """å¤„ç†ä¸Šä¼ çš„PDFæ–‡ä»¶ï¼Œä¿å­˜ã€åˆ‡åˆ†å¹¶åˆ›å»ºæˆ–æ›´æ–°å‘é‡ç´¢å¼•"""
    texts_with_metadata = []
    progress_bar = progress_placeholder.progress(0, text="å¼€å§‹å¤„ç†æ–‡ä»¶...")

    for i, pdf in enumerate(pdf_docs):
        file_path = os.path.join(FILES_DIR, pdf.name)
        with open(file_path, "wb") as f:
            f.write(pdf.getbuffer())

        pdf_reader = PdfReader(file_path)
        for page in pdf_reader.pages:
            text = page.extract_text()
            if text:
                text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
                chunks = text_splitter.split_text(text)
                for chunk in chunks:
                    texts_with_metadata.append((chunk, {"source": pdf.name}))

        progress_bar.progress((i + 1) / len(pdf_docs), text=f"æ­£åœ¨å¤„ç†: {pdf.name}")

    if not texts_with_metadata:
        progress_bar.empty()
        return 0

    texts = [item[0] for item in texts_with_metadata]
    metadatas = [item[1] for item in texts_with_metadata]

    if os.path.exists(INDEX_PATH):
        db = FAISS.load_local(INDEX_PATH, embeddings, allow_dangerous_deserialization=True)
        db.add_texts(texts, metadatas=metadatas)
    else:
        db = FAISS.from_texts(texts, embeddings, metadatas=metadatas)

    db.save_local(INDEX_PATH)
    progress_bar.progress(1.0, text="æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆï¼")
    return len(pdf_docs)

def process_uploaded_files(uploaded_files):
    pdf_docs = [f for f in uploaded_files if f.name.lower().endswith('.pdf')]
    csv_files = [f for f in uploaded_files if f.name.lower().endswith('.csv')]

    pdf_count, csv_loaded_name = 0, None
    progress_placeholder = st.empty()

    if pdf_docs:
        with st.spinner(f"æ­£åœ¨å¤„ç† {len(pdf_docs)} ä¸ªPDFæ–‡ä»¶..."):
            pdf_count = process_and_index_files(pdf_docs, progress_placeholder)

    if csv_files:
        csv_to_load = csv_files[0]
        try:
            st.session_state.df = pd.read_csv(csv_to_load)
            st.session_state.data_analysis_messages = [
                AIMessage(content=f"å·²æˆåŠŸåŠ è½½ `{csv_to_load.name}`ã€‚ç°åœ¨æ‚¨å¯ä»¥å¼€å§‹å¯¹è¿™ä¸ªè¡¨æ ¼æé—®äº†ã€‚")]
            st.session_state.dff = True
            if os.path.exists('plot.png'): os.remove('plot.png')
            csv_loaded_name = csv_to_load.name
            if len(csv_files) > 1:
                st.toast(f"åŠ è½½äº†ç¬¬ä¸€ä¸ªCSV: {csv_loaded_name} ç”¨äºåˆ†æã€‚", icon="âš ï¸")

        except Exception as e:
            st.error(f"åŠ è½½CSVæ–‡ä»¶ '{csv_to_load.name}' å¤±è´¥: {e}")

    progress_placeholder.empty()
    summary = []
    if pdf_count > 0: summary.append(f"æˆåŠŸå¤„ç†äº† {pdf_count} ä¸ªPDFã€‚")
    if csv_loaded_name:
        summary.append(f"åŠ è½½äº† '{csv_loaded_name}' ç”¨äºæ•°æ®åˆ†æã€‚")


    if summary:
        st.success(" ".join(summary)); time.sleep(2)
    else:
        st.warning("æ²¡æœ‰ä¸Šä¼ æœ‰æ•ˆçš„æ–‡ä»¶ç±»å‹ï¼ˆPDFæˆ–CSVï¼‰ã€‚")


def get_relevant_files(query):
    """æ ¹æ®æŸ¥è¯¢åœ¨æ•´ä¸ªæ•°æ®åº“ä¸­æ£€ç´¢ç›¸å…³æ–‡ä»¶å"""
    if not os.path.exists(INDEX_PATH):
        return []

    db = FAISS.load_local(INDEX_PATH, embeddings, allow_dangerous_deserialization=True)
    retriever = db.as_retriever(search_kwargs={'k': 20})
    relevant_docs = retriever.get_relevant_documents(query)

    return list(set(doc.metadata['source'] for doc in relevant_docs))


def get_agent_executor(selected_files=None,df=None):
    """åˆ›å»ºå¸¦æœ‰å·¥å…·çš„ Agent Executorã€‚å¦‚æœé€‰æ‹©äº†æ–‡ä»¶ï¼Œåˆ™æ–‡æ¡£æ£€ç´¢å™¨ä¼šè¢«è¿‡æ»¤"""
    search = TavilySearchResults(max_results=3)

    @tool
    def search_tool(query: str) -> str:
        """å½“ä½ éœ€è¦æœç´¢æœ€æ–°ä¿¡æ¯æˆ–ç”¨æˆ·é—®é¢˜ä¸æœ¬åœ°æ–‡æ¡£æ— å…³æ—¶ä½¿ç”¨æ­¤å·¥å…·ã€‚"""
        return search.invoke(query)

    tool1 = search_tool
    locals_dict = {'df': st.session_state.df}
    tool2 = PythonAstREPLTool(locals=locals_dict)


    tools = [tool1]
    if not st.session_state.data_active:
        pass
    else:
        tools.append(tool2)

    if df:
        aa = None
    else:
        aa = st.session_state.df.head().to_markdown()

    if selected_files and os.path.exists(INDEX_PATH):
        full_db = FAISS.load_local(INDEX_PATH, embeddings, allow_dangerous_deserialization=True)

        filtered_docs = []
        for doc_id, doc in full_db.docstore._dict.items():
            if doc.metadata.get("source") in selected_files:
                filtered_docs.append(doc)

        if filtered_docs:
            filtered_db = FAISS.from_documents(filtered_docs, embeddings)
            retriever = filtered_db.as_retriever(search_kwargs={'k': 10})  # å¢åŠ æ£€ç´¢æ•°é‡

            document_retriever_tool = create_retriever_tool(
                retriever,
                "document_retriever",
                f"ä¼˜å…ˆä½¿ç”¨æ­¤å·¥å…·å›ç­”å…³äºç‰¹å®šæ–‡æ¡£çš„é—®é¢˜ã€‚è¿™äº›æ˜¯ç”¨æˆ·æˆæƒä½ æŸ¥é˜…çš„æ–‡æ¡£ï¼š{', '.join(selected_files)}ã€‚"
            )
            tool3 = document_retriever_tool
            tools.append(tool3)


    llm = init_chat_model("deepseek-chat", model_provider="deepseek", temperature=0.7)

    system_prompt = f"""
## è§’è‰²ä¸ä»»åŠ¡

ä½ æ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„å¤šåŠŸèƒ½æ™ºèƒ½ä½“ã€‚ä½ çš„ä¸»è¦ç›®æ ‡æ˜¯åˆ†æç”¨æˆ·çš„è¯·æ±‚ï¼Œä»ä½ çš„å·¥å…·åº“ä¸­é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·ï¼Œæ‰§è¡Œå®ƒï¼Œç„¶åæ ¹æ®å·¥å…·çš„è¾“å‡ºå’Œè‡ªå·±çš„æ€è€ƒå½¢æˆæœ€ç»ˆç­”æ¡ˆã€‚

## å·¥å…·åº“

æœ‰ä»¥ä¸‹ä¸‰ç§å·¥å…·,ä½†ä½ å¯ä»¥ä½¿ç”¨é‡Œé¢çš„è‹¥å¹²ç§å·¥å…·,æ ¹æ®å®é™…æƒ…å†µå†³å®šï¼š

1.  **`web_search`**

      * **åŠŸèƒ½**: åœ¨äº’è”ç½‘ä¸Šæœç´¢å®æ—¶æˆ–å¸¸è¯†æ€§ä¿¡æ¯ã€‚
      * **ä½•æ—¶ä½¿ç”¨**: å½“é—®é¢˜æ¶‰åŠå½“å‰äº‹ä»¶ã€äº‹å®æˆ–ä»»ä½•æœªæ˜ç¡®åŒ…å«åœ¨ç”¨æˆ·ç§æœ‰æ–‡ä»¶ä¸­çš„ä¸»é¢˜æ—¶ä½¿ç”¨ã€‚è¿™æ˜¯ä½ å¤„ç†ä¸€èˆ¬æ€§æŸ¥è¯¢çš„é»˜è®¤å·¥å…·ã€‚

2.  **`document_retriever`**

      * **åŠŸèƒ½**: ä»ç”¨æˆ·å·²ä¸Šä¼ çš„PDFæ–‡æ¡£ä¸­æ£€ç´¢ç‰¹å®šä¿¡æ¯ã€‚
      * **ä½•æ—¶ä½¿ç”¨**: ä»…å½“ç”¨æˆ·çš„é—®é¢˜æ˜¯å…³äºä»–ä»¬ä¸Šä¼ çš„æ–‡ä»¶å†…å®¹æ—¶ä½¿ç”¨ï¼ˆä¾‹å¦‚ï¼Œâ€œåœ¨æˆ‘çš„æ–‡æ¡£ä¸­â€ã€â€œæ ¹æ®è¿™ç¯‡è®ºæ–‡â€ã€â€œæ€»ç»“è¿™ä¸ªæ–‡ä»¶â€ï¼‰ã€‚

3.  **`python_data_analyzer`**

      * **åŠŸèƒ½**: åœ¨ä¸€ä¸ªå·²åŠ è½½çš„CSVæ–‡ä»¶ä¸Šæ‰§è¡ŒPythonä»£ç ï¼Œè¯¥æ–‡ä»¶å¯ä½œä¸ºä¸€ä¸ªåä¸º `df` çš„Pandas DataFrame ä½¿ç”¨ã€‚
      * **ä½•æ—¶ä½¿ç”¨**: ä»…å½“é—®é¢˜éœ€è¦åŸºäºå·²åŠ è½½çš„æ•°æ®é›†è¿›è¡Œè®¡ç®—ã€æ•°æ®åˆ†ææˆ–ç»˜å›¾æ—¶ä½¿ç”¨ï¼ˆä¾‹å¦‚ï¼Œâ€œè®¡ç®—å¹³å‡å€¼â€ã€â€œç»˜åˆ¶å›¾è¡¨â€ã€â€œåˆ†ææ•°æ®â€ï¼‰ã€‚
      * **[å½“å‰æƒ…å¢ƒ]**
          * ä¸€ä¸ªCSVæ–‡ä»¶å½“å‰å·²è¢«åŠ è½½ã€‚DataFrame `df` å¯ç”¨äºåˆ†æã€‚
          * ä»¥ä¸‹æ˜¯ `df.head().to_markdown()` çš„è¾“å‡ºï¼Œä¾›ä½ å‚è€ƒ,å¦‚æœè¾“å‡ºä¸ºç©ºï¼Œä»£è¡¨æ­¤æ—¶æ²¡æœ‰'df'ä¾›ä½ è®¿é—®;ç›¸åï¼Œä½ å¯ä»¥è®¿é—®å®Œæ•´çš„ `df`ã€‚
    ```
    {aa}
    ```
``* **[ç»˜å›¾æŒ‡å—]** * å¦‚æœç”¨æˆ·è¦æ±‚ç»˜å›¾ 
1.  **ä½¿ç”¨ `matplotlib.pyplot` (åˆ«åä¸º `plt`)** æ¥åˆ›å»ºå›¾è¡¨ã€‚
2.  **ä¸ºæ¯å¼ å›¾ä¿å­˜ä¸ºå”¯ä¸€æ–‡ä»¶**: æ¯ç”Ÿæˆä¸€å¼ å›¾ï¼Œéƒ½å¿…é¡»å°†å…¶ä¿å­˜ä¸ºä¸€ä¸ªå”¯ä¸€çš„ `.png` æ–‡ä»¶ã€‚ä¾‹å¦‚ `pic\\age_histogram.png`, `pic\\salary_plot.png`ã€‚ä¸è¦é‡å¤ä½¿ç”¨ `pic\\plot.png`ã€‚
3.  **æœ€ç»ˆè¾“å‡ºæ ¼å¼**: å½“ä½ å®Œæˆæ‰€æœ‰ç»˜å›¾å¹¶ä¿å­˜æ–‡ä»¶åï¼Œä½ çš„æœ€ç»ˆã€å”¯ä¸€çš„è¾“å‡ºå¿…é¡»éµå¾ªä¸‹é¢çš„ç‰¹æ®Šæ ¼å¼ã€‚å¯¹äºä½ ç”Ÿæˆçš„æ¯ä¸€å¼ å›¾ï¼Œéƒ½åˆ›å»ºä¸€ä¸ª`GRAPH_BEGIN/GRAPH_END`å—ã€‚

    **æ ¼å¼æ¨¡æ¿:**
    ```text
    GRAPH_BEGIN
    file: [ä½ ä¿å­˜çš„ç¬¬ä¸€ä¸ªæ–‡ä»¶å.png]
    title: [ç¬¬ä¸€å¼ å›¾çš„ä¸­æ–‡æ ‡é¢˜]
    GRAPH_END
    GRAPH_BEGIN
    file: [ä½ ä¿å­˜çš„ç¬¬äºŒä¸ªæ–‡ä»¶å.png]
    title: [ç¬¬äºŒå¼ å›¾çš„ä¸­æ–‡æ ‡é¢˜]
    GRAPH_END
    ```
    **ç¤ºä¾‹**: ç”¨æˆ·é—®: "ç”»å‡ºå¹´é¾„çš„ç›´æ–¹å›¾å’Œè–ªæ°´çš„ç®±çº¿å›¾"
    ä½ çš„ä»£ç å·¥å…·è°ƒç”¨ä¼šæ‰§è¡Œä¸¤æ¬¡ä¿å­˜: `plt.savefig('age_hist.png')` å’Œ `plt.savefig('salary_box.png')`ã€‚
    ç„¶åï¼Œä½ çš„æœ€ç»ˆè¾“å‡º**å¿…é¡»æ˜¯**:
    ```text
    GRAPH_BEGIN
    file: age_hist.png
    title: ç”¨æˆ·å¹´é¾„åˆ†å¸ƒç›´æ–¹å›¾
    GRAPH_END
    GRAPH_BEGIN
    file: salary_box.png
    title: ç”¨æˆ·è–ªæ°´ç®±çº¿å›¾
    GRAPH_END
    ```
4.  **æ³¨æ„**: ç»˜åˆ¶å›¾è¡¨æ—¶è¯·ä½¿ç”¨è‹±æ–‡ï¼Œå› ä¸ºæœåŠ¡å™¨ç¯å¢ƒå¯èƒ½ç¼ºå°‘ä¸­æ–‡å­—ä½“ã€‚ä½†åœ¨ `title:` éƒ¨åˆ†è¯·ä½¿ç”¨ä¸­æ–‡ã€‚

## å…³é”®è¾“å‡ºæŒ‡ä»¤
**é‡è¦æç¤ºï¼š** ä½ çš„æ‰€æœ‰é¢å‘ç”¨æˆ·çš„æœ€ç»ˆå›ç­”ã€è§£é‡Šå’Œæ€»ç»“éƒ½**å¿…é¡»**ä½¿ç”¨**ç®€ä½“ä¸­æ–‡**ã€‚ä½ çš„å†…éƒ¨æ€è€ƒè¿‡ç¨‹å¯ä»¥æ˜¯è‹±æ–‡ï¼Œä½†äº¤ä»˜ç»™ç”¨æˆ·çš„æœ€ç»ˆç­”æ¡ˆå¿…é¡»æ˜¯æµç•…è‡ªç„¶çš„ä¸­æ–‡ã€‚

ç°åœ¨ï¼Œè¯·å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
"""
    prompt = ChatPromptTemplate.from_messages(
        [("system", system_prompt), ("human", "{input}"), ("placeholder", "{agent_scratchpad}")])

    agent = create_openai_tools_agent(llm, tools, prompt)
    return AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)


def run_agent_with_streaming(agent_executor, query, history):
    """è¿è¡Œ Agent å¹¶é€šè¿‡å›è°ƒå®ç°æµå¼è¾“å‡º"""

    class StreamingCallbackHandler(BaseCallbackHandler):
        def __init__(self, placeholder):
            self.placeholder = placeholder
            self.full_response = ""

        def on_llm_new_token(self, token: str, **kwargs: any) -> None:
            self.full_response += token
            self.placeholder.markdown(self.full_response + "â–Œ")  # ä½¿ç”¨å…‰æ ‡æ¨¡æ‹Ÿæ‰“å­—æ•ˆæœ

        def on_agent_action(self, action: AgentAction, **kwargs: any) -> any:
            tool_name = action.tool
            self.placeholder.markdown(f"æ­£åœ¨è°ƒç”¨å·¥å…·: `{tool_name}`...")

    placeholder = st.empty()
    streaming_handler = StreamingCallbackHandler(placeholder)

    response = agent_executor.invoke(
        {"input": query, "chat_history": history},
        config={"callbacks": [streaming_handler]}
    )

    output = response.get('output', 'å¤„ç†å‡ºé”™ï¼Œè¯·é‡è¯•ã€‚')
    placeholder.markdown(output)
    return output


# --- ä¸»ç¨‹åºç•Œé¢ ---
def start_new_chat():
    """é‡ç½®ä¼šè¯çŠ¶æ€ä»¥å¼€å§‹ä¸€ä¸ªæ–°çš„ä¸´æ—¶å¯¹è¯ï¼Œä½†å…ˆä¸ä¿å­˜æ–‡ä»¶ã€‚"""
    st.session_state.active_chat_file_path = None  # å…³é”®æ”¹åŠ¨ï¼šè·¯å¾„ä¸ºNoneè¡¨ç¤ºæœªä¿å­˜
    st.session_state.active_chat_title = "æ–°å¯¹è¯" # å¯ä»¥ç»™ä¸€ä¸ªä¸´æ—¶æ ‡é¢˜
    st.session_state.chat_history = [AIMessage(content="æ‚¨å¥½ï¼æ–°çš„å¯¹è¯å·²å¼€å¯ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨ï¼Ÿ")]
    st.session_state.file_selection = {"show": False, "query": None, "options": []}
    st.rerun()


@st.dialog("æ•°æ®è¯¦æƒ…")
def show_data_dialog():
    """ç”¨äºæ˜¾ç¤ºå½“å‰DataFrameä¿¡æ¯çš„å¼¹çª—"""
    st.markdown('<div class="custom-wide-dialog"></div>', unsafe_allow_html=True)
    st.markdown("#### æ•°æ®é¢„è§ˆ (å‰10è¡Œ)")
    st.dataframe(st.session_state.df.head(10))
    st.markdown("#### æ•°æ®ç»´åº¦")
    st.write(f"{st.session_state.df.shape[0]} è¡Œ Ã— {st.session_state.df.shape[1]} åˆ—")
    st.markdown("#### æ•°æ®åˆ—ä¿¡æ¯")
    buffer = StringIO()
    st.session_state.df.info(buf=buffer)
    st.text(buffer.getvalue())
    if st.button("å…³é—­", use_container_width=True):
        st.rerun()
    # st.markdown('</div>', unsafe_allow_html=True)

def render_message_content(content: str):
    """
    è§£ææ¶ˆæ¯å†…å®¹å¹¶ä»¥åˆé€‚çš„æ–¹å¼åœ¨ Streamlit ä¸­æ¸²æŸ“ã€‚
    å¦‚æœå†…å®¹åŒ…å« GRAPH_BEGIN æ ‡è®°ï¼Œåˆ™å°†å…¶è§£æä¸ºæ–‡æœ¬å’Œå›¾è¡¨ã€‚
    å¦åˆ™ï¼Œç›´æ¥æ˜¾ç¤ºä¸º Markdown æ–‡æœ¬ã€‚
    """
    # æ£€æŸ¥å†…å®¹ä¸­æ˜¯å¦åŒ…å«å›¾è¡¨æ ‡è®°
    if "GRAPH_BEGIN" in content:
        # åˆ†ç¦»å¯èƒ½çš„æ–‡æœ¬éƒ¨åˆ†å’Œå›¾è¡¨å®šä¹‰éƒ¨åˆ†
        parts = content.split("GRAPH_BEGIN", 1)
        text_analysis_part = parts[0].strip()
        graph_definition_part = "GRAPH_BEGIN" + parts[1]

        # 1. å¦‚æœæœ‰æ–‡æœ¬éƒ¨åˆ†ï¼Œå…ˆæ¸²æŸ“æ–‡æœ¬
        if text_analysis_part:
            st.markdown(text_analysis_part)

        # 2. è§£æå¹¶æ¸²æŸ“å›¾è¡¨
        try:
            graphs_data = graph_definition_part.strip().split("GRAPH_BEGIN")
            for graph_block in graphs_data:
                if "GRAPH_END" in graph_block:
                    file_path = None
                    title = "æœªå‘½åå›¾è¡¨"
                    lines = graph_block.strip().split('\n')
                    for line in lines:
                        if line.startswith("file:"):
                            file_path = line.replace("file:", "").strip()
                        if line.startswith("title:"):
                            title = line.replace("title:", "").strip()

                    if file_path and os.path.exists(file_path):
                        st.markdown(f"**{title}**")
                        st.image(file_path)
                    elif file_path:
                        st.error(f"å›¾è¡¨æ¸²æŸ“å¤±è´¥ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}")
        except Exception as e:
            st.error(f"è§£æå›¾è¡¨æ•°æ®æ—¶å‡ºé”™: {e}")
            st.text(content) # å¦‚æœè§£æå¤±è´¥ï¼Œæ˜¾ç¤ºåŸå§‹æ–‡æœ¬ä»¥ä¾¿è°ƒè¯•
    else:
        # å¦‚æœæ²¡æœ‰å›¾è¡¨æ ‡è®°ï¼Œç›´æ¥å°†å†…å®¹ä½œä¸º Markdown æ˜¾ç¤º
        st.markdown(content)

def main():
    setup_directories()

    def load_css(file_name):
        with open(file_name, "r", encoding="utf-8") as f:
            st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)

    load_css('style.css')

    # --- ä¼šè¯çŠ¶æ€åˆå§‹åŒ– ---
    if "chat_history" not in st.session_state:
        chat_files = sorted(
            [f for f in os.listdir(CHAT_HISTORY_DIR) if f.startswith("chat_") and f.endswith(".pkl")],
            reverse=True
        )
        if chat_files:
            latest_chat_file = chat_files[0]
            st.session_state.active_chat_file_path = os.path.join(CHAT_HISTORY_DIR, latest_chat_file)
            title, messages = load_chat_history(st.session_state.active_chat_file_path)
            st.session_state.active_chat_title = title
            st.session_state.chat_history = messages
        else:
            # é¦–æ¬¡è¿è¡Œæ—¶åˆ›å»ºç¬¬ä¸€ä¸ªå¯¹è¯
            start_new_chat()
            # st.rerun() ä¼šå¯¼è‡´ Streamlit é‡æ–°æ‰§è¡Œï¼Œæ‰€ä»¥è¿™é‡Œä¸éœ€è¦å†å†™ä»£ç 
    if 'df' not in st.session_state:
        st.session_state.df = None
        st.session_state.dff = False

    # --- ä¾§è¾¹æ  UI ---
    with st.sidebar:
        # st.divider()


        st.title("RAG Agent")
        # å½“å¯¹è¯å†å²>1æ¡æ—¶ï¼ˆå³ç”¨æˆ·å·²æé—®ï¼‰ï¼Œæ‰å…è®¸æ–°å»ºå¯¹è¯
        # a=st.empty()
        is_chatting = len(st.session_state.get("chat_history", [])) > 1
        if st.button("ğŸ“ æ–°å»ºå¯¹è¯", use_container_width=True, disabled=not is_chatting,type="primary"):
            start_new_chat()
        # st.divider()
        # st.subheader("ğŸ—“ï¸ å¯¹è¯å†å²")
        all_chats = sorted(
            [f for f in os.listdir(CHAT_HISTORY_DIR) if f.startswith("chat_") and f.endswith(".pkl")],
            reverse=True
        )
        st.divider()
        # st.subheader("ğŸ—“ï¸ å¯¹è¯å†å²")
        st.button("ğŸ—“ï¸ è¿‘æœŸå¯¹è¯", use_container_width=True)

        for chat_file in all_chats:
            file_path = os.path.join(CHAT_HISTORY_DIR, chat_file)
            title = get_chat_title_from_file(file_path)

            if not title:
                ts_str = chat_file.replace("chat_", "").replace(".pkl", "")
                try:
                    title = f"å¯¹è¯äº {datetime.strptime(ts_str, '%Y%m%d_%H%M%S').strftime('%y-%m-%d %H:%M')}"
                except ValueError:
                    title = "æœªçŸ¥å¯¹è¯"

            is_active = file_path == st.session_state.get("active_chat_file_path")
            label = f"**{title}**" if is_active else title

            if st.button(label, key=chat_file, use_container_width=True):
                st.session_state.active_chat_file_path = file_path
                title, messages = load_chat_history(file_path)
                st.session_state.active_chat_title = title
                st.session_state.chat_history = messages
                st.rerun()
        st.divider()

        uploaded_files = st.file_uploader("ä¸Šä¼ æ–‡ä»¶", accept_multiple_files=True,label_visibility="collapsed")

        if st.button("â–¶ï¸ å¼€å§‹å¤„ç†", disabled=not uploaded_files, use_container_width=True,type="primary"):
            csv_loaded_name = process_uploaded_files(uploaded_files)
            # print(st.session_state.df)
            st.rerun()
        # print(ccc)
        if st.button("ğŸ‘€ æŸ¥çœ‹æ•°æ®è¯¦æƒ…",disabled=not st.session_state.dff, use_container_width=True,type="primary"):
            show_data_dialog()
        st.divider()

        with st.expander("ğŸ“š æ–‡æ¡£åº“", expanded=True):


            indexed_files = [f for f in os.listdir(FILES_DIR) if f.endswith('.pdf')] if os.path.exists(
                    FILES_DIR) else []
            if indexed_files:
                st.caption(f"å½“å‰åº“ä¸­æœ‰ {len(indexed_files)} ä¸ªæ–‡æ¡£")
                for file_name in indexed_files:
                    st.markdown(f"ğŸ“„ {file_name}")
            else:
                st.info("æ–‡æ¡£åº“ä¸ºç©ºã€‚")
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰æ•°æ®", use_container_width=True, type="primary"):

                if 'confirm_delete' not in st.session_state:
                    st.session_state.confirm_delete = False

                @st.dialog("ç¡®è®¤åˆ é™¤")
                def confirm_delete_dialog():
                    st.warning("âš ï¸ æ‚¨ç¡®å®šè¦åˆ é™¤æ‰€æœ‰æ•°æ®å—ï¼Ÿæ­¤æ“ä½œæ— æ³•æ’¤é”€ï¼")
                    col1, col2 = st.columns([0.5,0.5])
                    with col1:
                        if st.button("å–æ¶ˆ",type="primary", use_container_width=True):
                            st.session_state.confirm_delete = False
                            st.rerun()

                    with col2:
                        if st.button("ç¡®è®¤åˆ é™¤", type="primary", use_container_width=True):
                            st.session_state.confirm_delete = True
                            if os.path.exists(DB_DIR): shutil.rmtree(DB_DIR)
                            if os.path.exists(CHAT_HISTORY_DIR): shutil.rmtree(CHAT_HISTORY_DIR)
                            st.session_state.clear()
                            st.success("æ•°æ®å·²æ¸…ç©ºã€‚")
                            time.sleep(1)
                            st.rerun()
                confirm_delete_dialog()


        st.divider()

    # --- ä¸»èŠå¤©ç•Œé¢ ---
    for message in st.session_state.get("chat_history", []):
        avatar = "ğŸ’¡" if isinstance(message, AIMessage) else "ğŸ§‘â€ğŸ’»"
        with st.chat_message(message.type, avatar=avatar):
            render_message_content(message.content)
            # st.write(message.content)

    if st.session_state.get("file_selection", {}).get("show"):
        # ... RAGé€‰æ‹©ç•Œé¢æ— å˜åŒ–
        with st.chat_message("ai", avatar="ğŸ’¡"):
            st.info("æ ¹æ®æ‚¨çš„é—®é¢˜ï¼Œæˆ‘æ‰¾åˆ°äº†è¿™äº›å¯èƒ½ç›¸å…³çš„æ–‡æ¡£ã€‚è¯·é€‰æ‹©æ‚¨å¸Œæœ›æˆ‘é‡ç‚¹æŸ¥é˜…çš„æ–‡ä»¶ï¼š")

            selected_files = st.multiselect(
                "é€‰æ‹©æ–‡æ¡£:",
                options=st.session_state.file_selection["options"],
                default=st.session_state.file_selection["options"],
                label_visibility="collapsed"
            )

            if st.button("åŸºäºæ‰€é€‰æ–‡ä»¶ç”Ÿæˆå›ç­”", type="primary"):
                query = st.session_state.file_selection["query"]
                # st.session_state.chat_history.append(HumanMessage(content=query))

                with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"):
                    st.write(query)

                with st.chat_message("ai", avatar="ğŸ’¡"):
                    with st.spinner("æ­£åœ¨åŸºäºæ–‡æ¡£æ€è€ƒ..."):
                        agent_executor = get_agent_executor(selected_files=selected_files,df= not st.session_state.dff)
                        final_query = f"è¯·å…ˆåˆ¤æ–­æ˜¯å¦éœ€è¦æä¾›çš„ `document_retriever` å·¥å…·æ¥å›ç­”ä»¥ä¸‹é—®é¢˜ï¼Œå¦‚æœéœ€è¦ï¼Œè¯·å…ˆè°ƒç”¨`document_retriever`è¿›è¡ŒèƒŒæ™¯çŸ¥è¯†çš„æ£€ç´¢ã€‚é—®é¢˜æ˜¯ï¼š{query}"
                        response_content = run_agent_with_streaming(agent_executor, final_query,
                                                                    st.session_state.chat_history[1:-1])

                st.session_state.chat_history.append(AIMessage(content=response_content))
                # å®æ—¶ä¿å­˜åˆ°å½“å‰æ¿€æ´»çš„å¯¹è¯æ–‡ä»¶ä¸­
                save_chat_history(st.session_state.active_chat_title, st.session_state.chat_history,
                                  st.session_state.active_chat_file_path)
                st.session_state.file_selection["show"] = False
                st.rerun()
    with st._bottom:
        controls_container = st.container()
        with controls_container:
            # ä½¿ç”¨åˆ—å¸ƒå±€å°†æ§ä»¶ç»„æ”¾ç½®åœ¨å·¦ä¾§
            view_cols = st.columns([0.6, 0.4])
            with view_cols[0]:
                st.markdown("**AI æ¨¡å¼é€‰æ‹©:**")
                # åœ¨å·¦ä¾§åˆ—å†…éƒ¨å†æ¬¡ä½¿ç”¨åˆ—ï¼Œè®©ä¸¤ä¸ªå¼€å…³ç´§æŒ¨ç€
                control_cols = st.columns(2)
                with control_cols[0]:
                    st.session_state.rag_active = st.toggle("æ–‡æ¡£é—®ç­”", value=False, help="å¯ç”¨æ­¤æ¨¡å¼åï¼ŒAIä¼šä¼˜å…ˆä»æ‚¨ä¸Šä¼ çš„PDFæ–‡æ¡£ä¸­å¯»æ‰¾ç­”æ¡ˆã€‚")
                with control_cols[1]:
                    # is_df_loaded = st.session_state.get('dff', False)
                    st.session_state.data_active = st.toggle("æ•°æ®åˆ†æ", value=False, disabled=not is_df_loaded, help="éœ€å…ˆä¸Šä¼ CSVæ–‡ä»¶ã€‚å¯ç”¨åï¼ŒAIå¯ä»¥å¯¹è¡¨æ ¼æ•°æ®è¿›è¡Œè®¡ç®—å’Œç»˜å›¾ã€‚")
        # coo,coo1,jiy = st.columns([0.2,0.2,0.6])
        # with coo:
        #     st.session_state.rag_active = st.toggle("RAG",value=False)
        # with coo1:
        #     st.session_state.data_active = st.toggle("Data", value=False)


    if user_query := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):

        is_new_chat = st.session_state.active_chat_file_path is None

        # å¦‚æœæ˜¯æ–°å¯¹è¯ï¼Œåœ¨å¤„ç†ä¹‹å‰å…ˆâ€œå›ºåŒ–â€å®ƒ
        if is_new_chat:
            # 1. ä¸ºæ–°å¯¹è¯åˆ›å»ºçœŸå®çš„æ–‡ä»¶è·¯å¾„å’Œæ ‡é¢˜
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            new_chat_filename = f"chat_{timestamp}.pkl"
            st.session_state.active_chat_file_path = os.path.join(CHAT_HISTORY_DIR, new_chat_filename)

            st.session_state.active_chat_title = generate_chat_title(user_query)

            # 2. å°†åŒ…å«ç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯çš„ä¼šè¯å†å²é¦–æ¬¡å†™å…¥æ–‡ä»¶
            # æ³¨æ„ï¼šæ­¤æ—¶ chat_history é‡Œå·²ç»æœ‰AIçš„æ¬¢è¿è¯­äº†ï¼Œç°åœ¨è¿½åŠ ç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
            st.session_state.chat_history.append(HumanMessage(content=user_query))
            save_chat_history(
                st.session_state.active_chat_title,
                st.session_state.chat_history,
                st.session_state.active_chat_file_path
            )
        else:
            # å¯¹äºå·²å­˜åœ¨çš„å¯¹è¯ï¼Œåªéœ€è¿½åŠ ç”¨æˆ·æ¶ˆæ¯
            st.session_state.chat_history.append(HumanMessage(content=user_query))

        # æ­£å¸¸ç»§ç»­AIå›å¤æµç¨‹
        with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"):
            st.write(user_query)
        if len(st.session_state.chat_history) == 2 and st.session_state.active_chat_title is None:
            new_title = generate_chat_title(user_query)
            st.session_state.active_chat_title = new_title
            # ç«‹å³ä¿å­˜æ–°æ ‡é¢˜
            save_chat_history(
                st.session_state.active_chat_title,
                st.session_state.chat_history,
                st.session_state.active_chat_file_path
            )

        # RAG or Web Search
        if st.session_state.rag_active and os.path.exists(INDEX_PATH):
            relevant_files = get_relevant_files(user_query)
            if relevant_files:
                st.session_state.file_selection = {"show": True, "query": user_query, "options": relevant_files}
                st.rerun()

        if not st.session_state.get("file_selection", {}).get("show"):
            with st.chat_message("ai", avatar="ğŸ’¡"):
                with st.spinner("æ€è€ƒä¸­..."):
                    agent_executor = get_agent_executor(df= not st.session_state.dff)
                    response_content = run_agent_with_streaming(agent_executor, user_query,
                                                                st.session_state.chat_history[1:-1])

            st.session_state.chat_history.append(AIMessage(content=response_content))
            # ä¿å­˜åŒ…å«AIå›å¤çš„å®Œæ•´å¯¹è¯
            save_chat_history(
                st.session_state.active_chat_title,
                st.session_state.chat_history,
                st.session_state.active_chat_file_path
            )
            st.rerun()


if __name__ == "__main__":
    main()
